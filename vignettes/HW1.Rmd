---
title: "HW1"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{HW1}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Question 0

## Question 0A: 
Joshua Yang


## Question 0B: 
I have read and understood the entire syllabus.



## Question 0C: 
I've taken BIOST 514, 515 and 523 which involves using R to perform simple and multiple linear regression, bootstrapping and other related statistical methods.



# Question 1

# Question 2: Simulating the Central Limit Theorem
## Question 2A: 
The input is the amount of the numbers you want to generate, then function will randomly assign the number to generate with one of the three distribution (Gaussian, Gamma, and Chi-square).
```{r}
source("https://raw.githubusercontent.com/linnykos/561_s2024_public/main/homework1/generate_data.R")

```
## Question 2B:
```{r}
library(ggplot2)
results <- data.frame(mean = numeric(), n = factor())

num_trials <- 10000

for (n in c(1, 2, 3, 5, 10, 100)) {
  means <- replicate(num_trials, mean(generate_data(n = n)))
  
  results <- rbind(results, data.frame(mean = means, n = as.factor(n)))
}


ggplot(results, aes(x = mean)) +
  geom_histogram(bins = 100, fill = "blue", color = "black") +
  facet_wrap(~ n, scales = "free", ncol = 3) +
  labs(title = "Histograms of Means for Different Values of n",
       x = "Mean",
       y = "Frequency") 
```


## Question 2C:
The plot demonstrates the Central Limit Theorem by showing that sample means from a mixed distribution converge towards a normal distribution as sample size increases, regardless of the original data's distribution.


# Quetsion 3
## Question 3A:
The head() function gives the first five rows of the dataset by default, it shows the real value; summary() on the other hand, gives the mean, medians, quantiles and number of NAs for the numeric columns, and for the columns wit string data, it will present what's the lenght of thee column, the class and the mode of the data from that column.
```{r}
df <- read.csv("https://raw.githubusercontent.com/linnykos/561_s2024_public/main/homework1/sea-ad.csv")
head(df)
summary(df)
```
## Question 3B:
```{r}
# dimensionality of df
print(dim(df))

# class of df
print(class(df))
```


## Question 3C:
```{r}
df$Age.at.Death <- ifelse(df$Age.at.Death == "90+", "90", df$Age.at.Death)

df$Age.at.Death <- as.numeric(df$Age.at.Death)

hist(df$Age.at.Death, main = "Histogram of Age at Death", xlab = "Age", ylab = "Frequency")

```


## Question 3D:
```{r}
df$Sex <- factor(df$Sex)
df$APOE4.Status <- factor(df$APOE4.Status)
df$Cognitive.Status <- factor(df$Cognitive.Status)
df$Braak <- factor(df$Braak)

```
## Question 3E:
```{r}
summary(df)
```
## Question 3F:
```{r}
table(df$Braak, df$Cognitive.Status)
```

## Question 3G:
The table suggests that higher Last.CASI.Score ranges are associated with a lower frequency of dementia, indicating a potential trend where higher cognitive scores correlate with a reduced likelihood of dementia.
```{r}

quintiles_Last_CASI_Score <- quantile(df$Last.CASI.Score, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE)

labels <- paste(
  round(quintiles_Last_CASI_Score[-length(quintiles_Last_CASI_Score)], digits = 2), # Start points (excluding the last)
  "-", 
  round(quintiles_Last_CASI_Score[-1], digits = 2), # End points (excluding the first)
  sep = ""
)


df$Last.CASI.Score.Quintiles <- cut(
  df$Last.CASI.Score, 
  breaks = quintiles_Last_CASI_Score, 
  include.lowest = TRUE, 
  labels = labels
)

table(df$Last.CASI.Score.Quintiles, df$Cognitive.Status)
```


